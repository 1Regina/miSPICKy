{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "%matplotlib notebook\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn\n",
    "from sklearn import model_selection, linear_model, svm, naive_bayes, neighbors, ensemble, metrics, datasets\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage.color import *\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import mahotas as mt\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "from PIL import Image\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "seed = random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load images\n",
    "class1 = 'Clean_Room'\n",
    "class2 = 'Messy_Room'\n",
    "class3 = 'Bad_Excuse'\n",
    "path_data = '/Users/regina/Desktop/Metis/Metis Projects/miSPICKy/dataset/'\n",
    "images_class1 = ['/Users/regina/Desktop/Metis/Metis Projects/miSPICKy/dataset/Clean_Room/{}'.format(i) for i in os.listdir(path_data+str(class1)) if str(class1) in i]\n",
    "images_class2 = ['/Users/regina/Desktop/Metis/Metis Projects/miSPICKy/dataset/Messy_Room/{}'.format(i) for i in os.listdir(path_data+str(class2)) if str(class2) in i]\n",
    "images_class3 = ['/Users/regina/Desktop/Metis/Metis Projects/miSPICKy/Bad_Excuse/{}'.format(i) for i in os.listdir(path_data+str(class2)) if str(class2) in i]\n",
    "# path_data = '/Users/shiheping/Documents/data_science_study/kaplan_metis_bootcamp/projects/project_3/artwork_images/image_training_classes/'\n",
    "# images_class1 = ['/Users/shiheping/Documents/data_science_study/kaplan_metis_bootcamp/projects/project_3/artwork_images/image_training_classes/symbolism/{}'.format(i) for i in os.listdir(path_data+str(class1)) if str(class1) in i]\n",
    "# images_class2 = ['/Users/shiheping/Documents/data_science_study/kaplan_metis_bootcamp/projects/project_3/artwork_images/image_training_classes/baroque/{}'.format(i) for i in os.listdir(path_data+str(class2)) if str(class2) in i]\n",
    "train_class1 = images_class1[:500]\n",
    "train_class2 = images_class2[:500]\n",
    "train_class3 = images_class3[:500]\n",
    "test_images = images_class1[500:600] + images_class2[500:600]+ images_class3[500:600]\n",
    "train_images = train_class1 + train_class2 + train_class3\n",
    "random.shuffle(train_images)\n",
    "random.shuffle(test_images)\n",
    "# clear useless list\n",
    "del images_class1\n",
    "del images_class2\n",
    "del images_class3\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 100\n",
    "ncolumns = 100\n",
    "channels = 3\n",
    "\n",
    "def create_features(img):\n",
    "    # read image\n",
    "    #open_image = cv2.imread(img,cv2.IMREAD_COLOR)\n",
    "    open_image = cv2.resize(cv2.imread(img,cv2.IMREAD_COLOR),(nrows,ncolumns),interpolation=cv2.INTER_CUBIC)\n",
    "    # convert to array\n",
    "    img_to_array = np.array(open_image)\n",
    "    # flatten three channel color image\n",
    "    color_features = img_to_array.flatten()\n",
    "    # convert image to greyscale\n",
    "    grey_image = rgb2grey(img_to_array)\n",
    "    # get HOG features from greyscale image\n",
    "    hog_features = hog(grey_image, block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "    # get Haralick (GLCM)\n",
    "    grayscale = cv2.cvtColor(open_image,cv2.COLOR_BGR2GRAY)\n",
    "    textures = mt.features.haralick(grayscale)\n",
    "    ht_mean = textures.mean(axis=0)\n",
    "    # combine color, hog features, Haralick into a single array\n",
    "    flat_features = np.hstack((color_features,hog_features,ht_mean))\n",
    "    return flat_features\n",
    "# Haralick Texture is used to quantify an image based on texture. The fundamental\n",
    "# concept involved in computing Haralick Texture features is the Gray Level Co-occurrence Matrix or GLCM.\n",
    "\n",
    "# Loop through images to preprocess\n",
    "def read_and_create_feature_matrix(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays:\n",
    "    X is an array of resized images\n",
    "    y is an array of labels\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for image in list_of_images:\n",
    "        image_features = create_features(image)\n",
    "        X.append(image_features)\n",
    "        if class1 in image:\n",
    "            y.append(1)\n",
    "        elif class2 in image:\n",
    "            y.append(0)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 100\n",
    "ncolumns = 100\n",
    "channels = 3\n",
    "\n",
    "def create_features(img):\n",
    "    # read image\n",
    "    #open_image = cv2.imread(img,cv2.IMREAD_COLOR)\n",
    "    open_image = cv2.resize(cv2.imread(img,cv2.IMREAD_COLOR),(nrows,ncolumns),interpolation=cv2.INTER_CUBIC)\n",
    "    # convert to array\n",
    "    img_to_array = np.array(open_image)\n",
    "    # flatten three channel color image\n",
    "    color_features = img_to_array.flatten()\n",
    "    # convert image to greyscale\n",
    "    grey_image = rgb2grey(img_to_array)\n",
    "    # get HOG features from greyscale image\n",
    "    hog_features = hog(grey_image, block_norm='L2-Hys', pixels_per_cell=(16, 16))\n",
    "    # get Haralick (GLCM)\n",
    "    grayscale = cv2.cvtColor(open_image,cv2.COLOR_BGR2GRAY)\n",
    "    textures = mt.features.haralick(grayscale)\n",
    "    ht_mean = textures.mean(axis=0)\n",
    "    # combine color, hog features, Haralick into a single array\n",
    "    flat_features = np.hstack((color_features,hog_features,ht_mean))\n",
    "    return flat_features\n",
    "# Haralick Texture is used to quantify an image based on texture. The fundamental\n",
    "# concept involved in computing Haralick Texture features is the Gray Level Co-occurrence Matrix or GLCM.\n",
    "\n",
    "# Loop through images to preprocess\n",
    "def read_and_create_feature_matrix(list_of_images):\n",
    "    \"\"\"\n",
    "    Returns two arrays:\n",
    "    X is an array of resized images\n",
    "    y is an array of labels\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for image in list_of_images:\n",
    "        image_features = create_features(image)\n",
    "        X.append(image_features)\n",
    "        if class1 in image:\n",
    "            y.append(1)\n",
    "        elif class2 in image:\n",
    "            y.append(0)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-14242c7bc188>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "display(Image.open(train_images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-14ea168d6def>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "print(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape is:  (0,)\n"
     ]
    }
   ],
   "source": [
    "# run create_feature_matrix on our dataframe of images\n",
    "X, y = read_and_create_feature_matrix(train_images)\n",
    "X_test, y_test = read_and_create_feature_matrix(test_images)\n",
    "# Scale feature matrix + PCA\n",
    "# get shape of feature matrix\n",
    "print('Feature matrix shape is: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape is:  (0,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-aa9085b2f207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# check function output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Feature matrix shape is: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# check function output\n",
    "print('Feature matrix shape is: ', y.shape)\n",
    "type(create_features(train_images[0]))\n",
    "A = []\n",
    "for i in range(3):\n",
    "    a = np.array(create_features(train_images[i]))\n",
    "    A.append(a)\n",
    "print(np.array(A).shape)\n",
    "print(np.array(cv2.imread(train_images[4],cv2.IMREAD_COLOR)).shape)\n",
    "print(create_features(train_images[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define standard scaler\n",
    "ss = StandardScaler()\n",
    "# run this on our feature matrix\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_test_scaled = ss.fit_transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "# use fit_transform to run PCA on our standardized matrix\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_test_pca = pca.fit_transform(X_test_scaled)\n",
    "# look at new shape\n",
    "print('PCA matrix shape is: ', X_pca.shape)\n",
    "print('PCA matrix shape is: ', X_test_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cross_validate_evaluate(X_train, y_train, X_test, y_test):\n",
    "    # instantiate classifier\n",
    "    svc = svm.SVC()\n",
    "    rfc = RandomForestClassifier(random_state=seed)\n",
    "    knn = KNeighborsClassifier()\n",
    "    gnb = GaussianNB()\n",
    "    xgb = XGBClassifier()\n",
    "    # GridsearchCV parameters\n",
    "    param_grid_svm = [\n",
    "      {'C': [1, 2, 5, 10, 100], 'kernel': ['linear']},\n",
    "      {'C': [1, 2, 5, 10, 100], 'gamma': [0.5, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "     {'C': [1, 2, 5, 10, 100], 'gamma': [0.5, 0.1, 0.01, 0.001, 0.0001], 'kernel': ['sigmoid']}]\n",
    "    param_grid_rfc = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,6,8,10],\n",
    "    'criterion' :['gini', 'entropy']}\n",
    "    param_grid_knn = {\n",
    "    'n_neighbors': [3,5,11,19],\n",
    "    'weights':['uniform','distance'],\n",
    "    'metric':['euclidean','manhattan']}\n",
    "    param_grid_xgb = {\n",
    "    'reg_alpha': [0.0, 1.0], \n",
    "    'reg_lambda': [0.0, 1.0],\n",
    "    'learning_rate': [0.1,0.01],\n",
    "    'n_estimators': [100, 200], \n",
    "    'seed': [seed]}\n",
    "    # GridSearchCV\n",
    "    score = 'f1_weighted'\n",
    "    clf = GridSearchCV(svc, param_grid_svm, cv=5, scoring=score, n_jobs = -1)\n",
    "    CV_rfc = GridSearchCV(rfc, param_grid=param_grid_rfc, cv= 5, scoring=score, n_jobs = -1)\n",
    "    CV_knn = GridSearchCV(knn, param_grid=param_grid_knn, cv= 5, scoring=score, n_jobs = -1)\n",
    "    CV_xgb = GridSearchCV(xgb, param_grid=param_grid_xgb, cv= 5, scoring=score, n_jobs = -1)\n",
    "    # train\n",
    "    clf.fit(X_train, y_train)\n",
    "    CV_rfc.fit(X_train, y_train)\n",
    "    CV_knn.fit(X_train, y_train)\n",
    "    gnb.fit(X_train,y_train)\n",
    "    CV_xgb.fit(X_train, y_train)\n",
    "    # predict\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(\"Best score: %.1f%%\" % (clf.best_score_*100))\n",
    "    print('SVM:', clf.best_params_)\n",
    "    print(\"Best score: %.1f%%\" % (CV_rfc.best_score_*100))\n",
    "    print('Random Forest:', CV_rfc.best_params_)\n",
    "    print(\"Best score: %.1f%%\" % (CV_knn.best_score_*100))\n",
    "    print('KNN:', CV_knn.best_params_)\n",
    "    print(\"Best score: %.1f%%\" % (CV_xgb.best_score_*100))\n",
    "    print('XGBoost:', CV_xgb.best_params_)\n",
    "    print()\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print(\"SVM:\")\n",
    "    y_true_svm, y_pred_svm = y_test, clf.best_estimator_.predict(X_test)\n",
    "    print(classification_report(y_true_svm, y_pred_svm))\n",
    "    print()\n",
    "    print(\"Random Forest:\")\n",
    "    y_true_rf, y_pred_rf = y_test, CV_rfc.best_estimator_.predict(X_test)\n",
    "    print(classification_report(y_true_rf, y_pred_rf))\n",
    "    print()\n",
    "    print(\"KNN:\")\n",
    "    y_true_knn, y_pred_knn = y_test, CV_knn.best_estimator_.predict(X_test)\n",
    "    print(classification_report(y_true_knn, y_pred_knn))\n",
    "    print()\n",
    "    print(\"Gaussian Naive Bayes:\")\n",
    "    #y_true_gnb, y_pred_gnb = y_test, gnb.predict(X_test)\n",
    "    print(gnb.score(X_test,y_test))\n",
    "    print()\n",
    "    print(\"XGBoost:\")\n",
    "    y_true_xgb, y_pred_xgb = y_test, CV_xgb.best_estimator_.predict(X_test)\n",
    "    print(classification_report(y_true_xgb, y_pred_xgb))\n",
    "    print()\n",
    "    return clf.best_params_, CV_rfc.best_params_, CV_knn.best_params_, CV_xgb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params, rfc_params, knn_params, xgb_params = train_cross_validate_evaluate(X_pca, y, X_test_pca, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "num_classes = 3\n",
    "b = np.array([0,2,1,1,2,0,2,0])\n",
    "b.reshape(-1) # your initial classes\n",
    "Y = np.eye(num_classes)[b]\n",
    "print(b)\n",
    "print(Y)\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
