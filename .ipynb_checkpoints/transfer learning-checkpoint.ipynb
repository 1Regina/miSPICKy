{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\regina\\Desktop\\Metis\\Metis Projects\\Spark\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# USAGE\n",
    "# python train_vgg.py --dataset animals --model output/smallvggnet.model --label-bin output/smallvggnet_lb.pickle --plot output/smallvggnet_plot.png\n",
    "\n",
    "\n",
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# matplotlib.use(\"Agg\")\n",
    "\n",
    "# import the necessary packages\n",
    "from pyimagesearch.smallvggnet import SmallVGGNet\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "                help=\"path to input dataset of images\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "                help=\"path to output trained model\")\n",
    "ap.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "                help=\"path to output label binarizer\")\n",
    "ap.add_argument(\"-p\", \"--plot\", required=True,\n",
    "                help=\"path to output accuracy/loss plot\")\n",
    "args = vars(ap.parse_args())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images('dataset')))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, resize the image to be 32x32 pixels (ignoring\n",
    "    # aspect ratio), flatten the image into 32x32x3=3072 pixel image\n",
    "    # into a list, and store the image in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    data.append(image)\n",
    " \n",
    "    # extract the class label from the image path and update the labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the labels from integers to vectors \n",
    "# (for 2-class, binary classification you should use Keras' to_categorical \n",
    "# function instead as the scikit-learn's LabelBinarizer will not return a vector)\n",
    "lb = LabelBinarizer()\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "                         horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# initialize our VGG-like Convolutional Neural Network\n",
    "model = SmallVGGNet.build(width=64, height=64, depth=3,\n",
    "classes=len(lb.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our initial learning rate, # of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 0.01\n",
    "EPOCHS = 75\n",
    "BS = 32\n",
    "\n",
    "# initialize the model and optimizer (you'll want to use\n",
    "# binary_crossentropy for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "opt = SGD(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "                       validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "                       epochs=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=32)\n",
    "print(classification_report(testY.argmax(axis=1),predictions.argmax(axis=1), target_names=lb.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = np.arange(0, EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(N, H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy (SmallVGGNet)\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend()\n",
    "plt.savefig(\"plot\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and label binarizer to disk\n",
    "print(\"[INFO] serializing network and label binarizer...\")\n",
    "model.save(\"trsf_learning_model\")\n",
    "f = open(\"label_bin2\", \"wb\")\n",
    "f.write(pickle.dumps(lb))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from keras.models import load_model\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "width = 64\n",
    "height = 64\n",
    "image = cv2.imread(\"images\\bad_excuse1.jpg\")\n",
    "output = image.copy()\n",
    "image = cv2.resize(image, (width, height)).flatten()\n",
    "image = image.reshape((1, image.shape[0]))\n",
    "# scale the pixel values to [0, 1]\n",
    "image = image.astype(\"float\") / 255.0\n",
    "# # check to see if we should flatten the image and add a batch dimension\n",
    "# if flatten > 0:\n",
    "#     image = image.flatten()\n",
    "#     image = image.reshape((1, image.shape[0]))\n",
    "# # otherwise, we must be working with a CNN -- don't flatten the\n",
    "# # image, simply add the batch dimension\n",
    "# else:\n",
    "#     image = image.reshape((1, image.shape[0], image.shape[1],\n",
    "#         image.shape[2]))\n",
    "# load the model and label binarizer\n",
    "print(\"[INFO] loading network and label binarizer...\")\n",
    "model = load_model('trsf_learning_model') ## update\n",
    "lb = pickle.loads(open(\"label_bin2\", \"rb\").read()) ## update\n",
    "# make a prediction on the image\n",
    "preds = model.predict(image)\n",
    "# find the class label index with the largest corresponding probability\n",
    "i = preds.argmax(axis=1)[0]\n",
    "label = lb.classes_[i]\n",
    "# draw the class label + probability on the output image\n",
    "text = \"{}: {:.2f}%\".format(label, preds[0][i] * 100)\n",
    "cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "# show the output image\n",
    "cv2.imshow(\"Image\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
